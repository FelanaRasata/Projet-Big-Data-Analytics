{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8a3afc-2136-465e-9ba4-9e2436d7d544",
   "metadata": {},
   "source": [
    "# Analyse de données et modèle de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ffab5-a430-4c7e-8851-26a16dcb6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ac38b6-f1a6-4fc6-b1b2-1ffaffbc4957",
   "metadata": {},
   "source": [
    "### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e672b5d-0e0b-4803-b389-eb94eaad73fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Vehicle Category Prediction\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c72c84e-b78e-43ee-902c-be87f7df0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df(df):\n",
    "    print(\"Size\", df.count())\n",
    "    df.printSchema()\n",
    "    df.show(5)\n",
    "\n",
    "def load_data_in_csv_file(file_path):\n",
    "    df = spark.read.options(delimiter=\",\", header=True, inferSchema=True).csv(file_path)\n",
    "\n",
    "    # Display schema and first five rows of the DataFrame\n",
    "    print(\"Schema and first rows in\", file_path)\n",
    "    print_df(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8be30c-8124-4371-8200-c15927559cd0",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f0965-dc63-48a5-bca0-40956436bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path in Hadoop FS\n",
    "hdfs_path = \"hdfs:///tpa_groupe_14/data/fusion/fusion.csv\"\n",
    "\n",
    "# Load CSV data into a DataFrame\n",
    "vehicles_df = load_data_in_csv_file(hdfs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7606c5ce-9c06-4921-8b31-53eb574aedff",
   "metadata": {},
   "source": [
    "### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19cde1-9c80-4378-8b63-cb1ed42f8141",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = vehicles_df.schema.names\n",
    "\n",
    "for column_name in column_names:\n",
    "    vehicles_df = vehicles_df.withColumnRenamed(column_name, column_name.replace(\".\", \"_\"))\n",
    "\n",
    "print_df(vehicles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601cfd3-c2c8-4f03-908d-b3b816599423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f9301d-14fd-49be-910e-761d0be68e6a",
   "metadata": {},
   "source": [
    "### Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a21d6b2-dc73-4879-80af-e99ed132dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Sub-sample the DataFrame\n",
    "vehicles_df = vehicles_df.sample(withReplacement=False, fraction=0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da9f51-55f9-4eb3-bfa7-e56b6ca7dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(vehicles_df)\n",
    "    for column in [\"client_view_sexe\", \"client_view_situationfamiliale\", \"immatriculation_co2_view_categorie\"]\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"client_view_age\", \"client_view_taux\", \"client_view_nbenfantsacharge\", \"client_view_deuxiemevoiture\",\n",
    "        \"client_view_sexe_index\", \"client_view_situationfamiliale_index\"\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Split the DataFrame into training and test sets (80% training, 20% test)\n",
    "train_df, test_df = vehicles_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "train_df = pipeline_model.transform(train_df)\n",
    "test_df = pipeline_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45d78e0-874d-49df-8ebf-ce25ac3ead1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ffe874-0c41-4fe4-9d56-f4b8df9afbd4",
   "metadata": {},
   "source": [
    "# La précision & Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d5d26-9666-4e11-bed3-1dd715b05576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_classifier(classifier, param_grid, train_df, test_df, title):\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"immatriculation_co2_view_categorie_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    \n",
    "    # Create the cross-validator\n",
    "    cross_validator = CrossValidator(\n",
    "        estimator=classifier,\n",
    "        estimatorParamMaps=param_grid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=3, \n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Train the model with the best hyperparameters\n",
    "    cv_model = cross_validator.fit(train_df)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    predictions = cv_model.transform(test_df)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "    # Calcul de la matrice de confusion\n",
    "    predictions_and_labels = predictions.select(\"prediction\", \"immatriculation_co2_view_categorie_index\")\n",
    "    prediction_rdd = predictions_and_labels.rdd.map(tuple)\n",
    "    \n",
    "    metrics = MulticlassMetrics(prediction_rdd)\n",
    "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    # Calcul des taux de succès par classe\n",
    "    labels = metrics.labels\n",
    "    per_class_metrics = {}\n",
    "    for label in labels:\n",
    "        per_class_metrics[label] = {\n",
    "            \"precision\": metrics.precision(label),\n",
    "            \"recall\": metrics.recall(label),\n",
    "            \"f1_score\": metrics.fMeasure(label)\n",
    "        }\n",
    "    \n",
    "    # Calcul des métriques globales pondérées\n",
    "    weighted_metrics = {\n",
    "        \"precision\": metrics.weightedPrecision,\n",
    "        \"recall\": metrics.weightedRecall,\n",
    "        \"f1_score\": metrics.weightedFMeasure(),\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "    print(f\"{title} Accuracy = {:.2f}\".format(accuracy))\n",
    "    print(f\"{title} Confusion Matrix:\\n\", confusion_matrix)\n",
    "\n",
    "        \n",
    "    print(\"\\nPar Classe Metrics:\")\n",
    "    for label, metrics in per_class_metrics.items():\n",
    "        print(f\" Class {label}:\")\n",
    "        print(f\"  Precision: {metrics['precision']:.2f}\")\n",
    "        print(f\"  Recall: {metrics['recall']:.2f}\")\n",
    "        print(f\"  F1 Score: {metrics['f1_score']:.2f}\")\n",
    "    \n",
    "    print(\"\\nWeighted Metrics:\")\n",
    "    print(f\"  Weighted Precision: {weighted_metrics['precision']:.2f}\")\n",
    "    print(f\"  Weighted Recall: {weighted_metrics['recall']:.2f}\")\n",
    "    print(f\"  Weighted F1 Score: {weighted_metrics['f1_score']:.2f}\")\n",
    "    print(f\"  Accuracy: {weighted_metrics['accuracy']:.2f}\")\n",
    "    \n",
    "    return cv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5377d5-6375-46ec-8d74-5473b01ffc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (\n",
    "    DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, \n",
    "    LinearSVC, LogisticRegression, MultilayerPerceptronClassifier, NaiveBayes, OneVsRest\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3276bf-7e86-4cf7-99b2-a11a90358cc6",
   "metadata": {},
   "source": [
    "1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cda53f-4c88-40e7-81cd-2297f3938a0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"immatriculation_co2_view_categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "rf_model = evaluate_classifier(\n",
    "    classifier=rf,\n",
    "    param_grid=rf_param_grid,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df;\n",
    "    title='RandomForestClassifier'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990bb322-557e-4e67-a2dc-e37cbcf9da7f",
   "metadata": {},
   "source": [
    "2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e3ef8-ff53-4328-8485-6a0840c6beed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"immatriculation_co2_view_categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "dt_param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(dt.maxDepth, [5, 10])\\\n",
    "    .addGrid(dt.impurity, [\"gini\", \"entropy\"])\\\n",
    "    .build()\n",
    "\n",
    "dt_model = evaluate_classifier(\n",
    "    classifier=dt,\n",
    "    param_grid=dt_param_grid,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    title='DecisionTreeClassifier'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cedc84-af56-4103-ab59-adbcd348c5ce",
   "metadata": {},
   "source": [
    "3. Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d10f9-f332-4186-b542-01da3addb6bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(labelCol=\"immatriculation_co2_view_categorie_index\", featuresCol=\"features\")\n",
    "ovr = OneVsRest(classifier=gbt, labelCol=\"immatriculation_co2_view_categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "gbt_param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(gbt.maxIter, [10, 20])\\\n",
    "    .addGrid(gbt.maxDepth, [5, 10])\\\n",
    "    .build()\n",
    "\n",
    "gbt_model = evaluate_classifier(\n",
    "    classifier=ovr,\n",
    "    param_grid=gbt_param_grid,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    title='GBTClassifier'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c4373b-2000-435f-a40e-124042f0602d",
   "metadata": {},
   "source": [
    "4. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce193681-fd4f-463a-8279-ce52adc64d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(labelCol=\"immatriculation_co2_view_categorie_index\", featuresCol=\"features\")\n",
    "ovr = OneVsRest(classifier=svm, labelCol=\"immatriculation_co2_view_categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "svm_param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(svm.maxIter, [10, 20])\\\n",
    "    .addGrid(svm.regParam, [0.01, 0.1])\\\n",
    "    .build()\n",
    "\n",
    "svm_model = evaluate_classifier(\n",
    "    classifier=ovr,\n",
    "    param_grid=svm_param_grid,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    title='LinearSVC'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c964ee20-7b36-462d-92e4-51d709311ecd",
   "metadata": {},
   "source": [
    "5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9fa7b-4a66-4a48-89fe-407df94688ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"immatriculation_co2_view_categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "lr_param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.maxIter, [10, 20])\\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "lr_model = evaluate_classifier(\n",
    "    classifier=lr,\n",
    "    param_grid=lr_param_grid,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    title='LogisticRegression'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd70f1-0029-48d2-ac4b-ecc41100cc2e",
   "metadata": {},
   "source": [
    "6. Neural Networks (Multilayer Perceptron Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821ec66d-8689-48f9-bb2f-1e39b995bd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = train_df.select(\"immatriculation_co2_view_categorie_index\").distinct().count()\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(labelCol=\"immatriculation_co2_view_categorie_index\", featuresCol=\"features\", layers=[6, 5, 4, num_classes])\n",
    "\n",
    "mlp_param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(mlp.maxIter, [50, 100])\\\n",
    "    .build()\n",
    "\n",
    "mlp_model = evaluate_classifier(\n",
    "    classifier=mlp,\n",
    "    param_grid=mlp_param_grid,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    title='MultilayerPerceptronClassifier'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e0df4-d24f-4d55-a397-e9ecca823e6c",
   "metadata": {},
   "source": [
    "7. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5169a-4733-4d59-bc46-f9a072335c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(labelCol=\"immatriculation_co2_view_categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "nb_param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(nb.smoothing, [0.5, 1.0, 1.5])\\\n",
    "    .build()\n",
    "\n",
    "nb_model = evaluate_classifier(\n",
    "    classifier=nb,\n",
    "    param_grid=nb_param_grid,\n",
    "    train_df=train_df,\n",
    "    test_df=test_df,\n",
    "    title='NaiveBayes'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e5a24",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b410e53",
   "metadata": {},
   "source": [
    "- Charger Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b6ab53-5731-458e-8ddf-70fddd426d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad6a48-7294-4683-b6fc-da3ed7f0ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hive_host = 'localhost'\n",
    "hive_port = 10000\n",
    "hive_username = ' ' \n",
    "hive_password = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606e686-72d5-48b6-a519-a0d01d812c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn = None\n",
    "try:\n",
    "    # Établir une connexion avec authentification LDAP\n",
    "    conn = hive.Connection(\n",
    "        host=hive_host,\n",
    "        port=hive_port,\n",
    "        username=hive_username,\n",
    "        password=hive_password,\n",
    "        auth='LDAP'  \n",
    "    )\n",
    "    print(\"Connecté à Hive avec succès\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la connexion à Hive: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ea5f5-d599-44db-a51b-c6d86aaeeded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un curseur\n",
    "cursor=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c2ecc1-37b7-4e37-acf8-91adc79f2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAll(table) :\n",
    "    # Exécuter une requête pour récupérer les données de la table \"catalogue\"\n",
    "    query = \"SELECT * FROM \" + table\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Charger les résultats dans un DataFrame Pandas\n",
    "    data = cursor.fetchall()\n",
    "\n",
    "    # Récupérer les noms des colonnes\n",
    "    columns = [desc[0] for desc in cursor.description] \n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    print(\"Select all \",table)\n",
    "\n",
    "    display(df.head())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing_df = findAll(\"marketing_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae8a830",
   "metadata": {},
   "source": [
    "Prétraiter les Données Marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommer les colonnes pour éviter les conflits\n",
    "for column_name in marketing_df.columns:\n",
    "    marketing_df = marketing_df.withColumnRenamed(column_name, column_name.replace(\".\", \"_\"))\n",
    "\n",
    "# Utiliser le pipeline formé précédemment pour transformer les données\n",
    "marketing_df = pipeline_model.transform(marketing_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c1dbf",
   "metadata": {},
   "source": [
    "Appliquer le Modèle de Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8302c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser le modèle formé pour faire des prédictions sur les données Marketing\n",
    "predictions = rf_model.transform(marketing_df)\n",
    "\n",
    "# Sélectionner les colonnes pertinentes pour l'affichage\n",
    "results = predictions.select(\"client_view_id\", \"prediction\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c0b6c",
   "metadata": {},
   "source": [
    "Exporter les Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdda16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin de sortie pour les résultats\n",
    "results_hdfs_path = \"hdfs:///tpa_groupe_14/results/marketing_predictions.csv\"\n",
    "\n",
    "# Sauvegarder les résultats dans HDFS\n",
    "results.write.csv(results_hdfs_path, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

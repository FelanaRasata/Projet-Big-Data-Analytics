{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b8a3afc-2136-465e-9ba4-9e2436d7d544",
   "metadata": {},
   "source": [
    "# Analyse de données et modèle de prédiction"
   ]
  },
  {
   "cell_type": "code",
   "id": "d55ffab5-a430-4c7e-8851-26a16dcb6d86",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "84ac38b6-f1a6-4fc6-b1b2-1ffaffbc4957",
   "metadata": {},
   "source": [
    "### Initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "id": "0e672b5d-0e0b-4803-b389-eb94eaad73fe",
   "metadata": {},
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Vehicle Category Prediction\") \\\n",
    "    .getOrCreate()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c72c84e-b78e-43ee-902c-be87f7df0528",
   "metadata": {},
   "source": [
    "def print_df(df):\n",
    "    print(\"Size\", df.count())\n",
    "    df.printSchema()\n",
    "    df.show(5)\n",
    "\n",
    "def load_data_in_csv_file(file_path, delimit = \",\", head=True):\n",
    "    df = spark.read.options(delimiter=\",\", header=True, inferSchema=True).csv(file_path)\n",
    "\n",
    "    # Display schema and first five rows of the DataFrame\n",
    "    print(\"Schema and first rows in\", file_path)\n",
    "    print_df(df)\n",
    "    \n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7d8be30c-8124-4371-8200-c15927559cd0",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "560f0965-dc63-48a5-bca0-40956436bc6a",
   "metadata": {},
   "source": [
    "# File path in Hadoop FS\n",
    "hdfs_path = \"hdfs:///tpa_groupe_14/data/fusion/fusion.csv\"\n",
    "\n",
    "# Load CSV data into a DataFrame\n",
    "vehicles_df = load_data_in_csv_file(hdfs_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7606c5ce-9c06-4921-8b31-53eb574aedff",
   "metadata": {},
   "source": [
    "### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "id": "ec19cde1-9c80-4378-8b63-cb1ed42f8141",
   "metadata": {},
   "source": [
    "column_names = vehicles_df.schema.names\n",
    "\n",
    "for column_name in column_names:\n",
    "    vehicles_df = vehicles_df.withColumnRenamed(column_name, column_name.split(\".\")[-1])\n",
    "\n",
    "print_df(vehicles_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3601cfd3-c2c8-4f03-908d-b3b816599423",
   "metadata": {},
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "61f9301d-14fd-49be-910e-761d0be68e6a",
   "metadata": {},
   "source": [
    "### Optional"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a21d6b2-dc73-4879-80af-e99ed132dd1c",
   "metadata": {},
   "source": [
    "# Optional: Sub-sample the DataFrame\n",
    "vehicles_df = vehicles_df.sample(withReplacement=False, fraction=0.3, seed=42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85b800ef-be0c-4649-aa1d-19e1a15b036d",
   "metadata": {},
   "source": [
    "train_df.show(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62da9f51-55f9-4eb3-bfa7-e56b6ca7dcfb",
   "metadata": {},
   "source": [
    "# Prepare features\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(vehicles_df)\n",
    "    for column in [\"sexe\", \"situationfamiliale\", \"categorie\"]\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"age\", \"taux\", \"nbenfantsacharge\", \"deuxiemevoiture\",\n",
    "        \"sexe_index\", \"situationfamiliale_index\"\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Split the DataFrame into training and test sets (80% training, 20% test)\n",
    "train_df, test_df = vehicles_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "pipeline_model = pipeline.fit(train_df)\n",
    "\n",
    "train_df = pipeline_model.transform(train_df)\n",
    "test_df = pipeline_model.transform(test_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01805fe4-0d7a-488f-a5f5-a04c8a15457e",
   "metadata": {},
   "source": [
    "label_predictions = test_df.select(\"categorie\", \"categorie_index\").distinct().rdd.collect()\n",
    "categorie_dict = {row['categorie_index']: row['categorie'] for row in label_predictions}\n",
    "\n",
    "print(categorie_dict)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d45d78e0-874d-49df-8ebf-ce25ac3ead1e",
   "metadata": {},
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "53ffe874-0c41-4fe4-9d56-f4b8df9afbd4",
   "metadata": {},
   "source": [
    "# La précision & Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce5d5d26-9666-4e11-bed3-1dd715b05576",
   "metadata": {},
   "source": [
    "# Evaluation function\n",
    "def evaluate_classifier(classifier, param_grid, train_df, test_df, title):\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"categorie_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    \n",
    "    # Create the cross-validator\n",
    "    cross_validator = CrossValidator(\n",
    "        estimator=classifier,\n",
    "        estimatorParamMaps=param_grid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=3, \n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Train the model with the best hyperparameters\n",
    "    cv_model = cross_validator.fit(train_df)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    predictions = cv_model.transform(test_df)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    \n",
    "    # Calcul de la matrice de confusion\n",
    "    predictions_and_labels = predictions.select(\"prediction\", \"categorie_index\")\n",
    "    prediction_rdd = predictions_and_labels.rdd.map(tuple)\n",
    "    \n",
    "    metrics = MulticlassMetrics(prediction_rdd)\n",
    "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    # Calcul des taux de succès par classe\n",
    "    labels = predictions.select(\"categorie_index\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "    \n",
    "    per_class_metrics = {}\n",
    "    for label in labels:\n",
    "        per_class_metrics[label] = {\n",
    "            \"precision\": metrics.precision(label),\n",
    "            \"recall\": metrics.recall(label),\n",
    "            \"f1_score\": metrics.fMeasure(label)\n",
    "        }\n",
    "    \n",
    "    # Calcul des métriques globales pondérées\n",
    "    weighted_metrics = {\n",
    "        \"precision\": metrics.weightedPrecision,\n",
    "        \"recall\": metrics.weightedRecall,\n",
    "        \"f1_score\": metrics.weightedFMeasure(),\n",
    "        \"accuracy\": accuracy\n",
    "    }\n",
    "\n",
    "    print(title + \" Accuracy = {:.2f}\".format(accuracy))\n",
    "    print(\"\\nWeighted Metrics:\")\n",
    "    print(f\"  Weighted Precision: {weighted_metrics['precision']:.2f}\")\n",
    "    print(f\"  Weighted Recall: {weighted_metrics['recall']:.2f}\")\n",
    "    print(f\"  Weighted F1 Score: {weighted_metrics['f1_score']:.2f}\")\n",
    "    print(f\"  Accuracy: {weighted_metrics['accuracy']:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        \"classifier\": title,\n",
    "        \"cv_model\": cv_model,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"confusion_matrix\": confusion_matrix,\n",
    "        \"per_class_metrics\": per_class_metrics,\n",
    "        \"weighted_metrics\": weighted_metrics\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2c5377d5-6375-46ec-8d74-5473b01ffc89",
   "metadata": {},
   "source": [
    "from pyspark.ml.classification import (\n",
    "    DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, \n",
    "    LinearSVC, LogisticRegression, MultilayerPerceptronClassifier, NaiveBayes, OneVsRest\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e497de08-0e89-447b-aa9c-d75222920bea",
   "metadata": {},
   "source": [
    "def calculate_composite_score(metrics, weights):\n",
    "    score = 0\n",
    "    \n",
    "    for metric, value in metrics.items():\n",
    "        score += weights.get(metric, 0) * value\n",
    "        \n",
    "    return score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c5a16800-4a48-4920-82b6-0abf7d421058",
   "metadata": {},
   "source": [
    "def compare_classifiers(classifiers, param_grids, train_df, test_df, titles):\n",
    "    results = []\n",
    "    \n",
    "    for classifier, param_grid, title in zip(classifiers, param_grids, titles):\n",
    "        print(f\"\\nEvaluating {title}...\\n\")\n",
    "        result = evaluate_classifier(classifier, param_grid, train_df, test_df, title)\n",
    "        weighted_metrics = result['weighted_metrics']\n",
    "        composite_score = calculate_composite_score(weighted_metrics, weighted_metrics)\n",
    "        results.append({ \"composite_score\": composite_score, \"cv_model\": result[\"cv_model\"], \"classifier\": result[\"classifier\"] })\n",
    "    \n",
    "    # Rank the models based on composite scores\n",
    "    ranked_results = sorted(results, key=lambda item: item[\"composite_score\"], reverse=True)\n",
    "\n",
    "    print(\"Model with highest score:\", ranked_results[0][\"classifier\"], \"[\", ranked_results[0][\"composite_score\"], \"]\")\n",
    "    \n",
    "    return ranked_results[0][\"cv_model\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ee3276bf-7e86-4cf7-99b2-a11a90358cc6",
   "metadata": {},
   "source": [
    "## Entrainement et comparaison des modèles"
   ]
  },
  {
   "cell_type": "code",
   "id": "d8bd1b95-f500-452a-bd16-fdf04ce6bc89",
   "metadata": {},
   "source": [
    "rf = RandomForestClassifier(labelCol=\"categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "rf_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "dt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [5, 10]) \\\n",
    "    .addGrid(dt.impurity, [\"gini\", \"entropy\"]) \\\n",
    "    .build()\n",
    "\n",
    "gbt = GBTClassifier(labelCol=\"categorie_index\", featuresCol=\"features\")\n",
    "gbt_ovr = OneVsRest(classifier=gbt, labelCol=\"categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "gbt_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [10, 20]) \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "svm = LinearSVC(labelCol=\"categorie_index\", featuresCol=\"features\")\n",
    "svm_ovr = OneVsRest(classifier=svm, labelCol=\"categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "svm_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.maxIter, [10, 20]) \\\n",
    "    .addGrid(svm.regParam, [0.01, 0.1]) \\\n",
    "    .build()\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "lr_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [10, 20]) \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "num_classes = train_df.select(\"categorie_index\").distinct().count()\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(labelCol=\"categorie_index\", featuresCol=\"features\", layers=[6, 5, 4, num_classes])\n",
    "\n",
    "mlp_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(mlp.maxIter, [50, 100]) \\\n",
    "    .build()\n",
    "\n",
    "nb = NaiveBayes(labelCol=\"categorie_index\", featuresCol=\"features\")\n",
    "\n",
    "nb_param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(nb.smoothing, [0.5, 1.0, 1.5]) \\\n",
    "    .build()\n",
    "\n",
    "classifiers = [\n",
    "    rf,\n",
    "    dt, \n",
    "    gbt_ovr,\n",
    "    svm_ovr,\n",
    "    lr,\n",
    "    mlp,\n",
    "    nb\n",
    "]\n",
    "\n",
    "param_grids = [\n",
    "    rf_param_grid,\n",
    "    dt_param_grid, \n",
    "    gbt_param_grid,\n",
    "    svm_param_grid,\n",
    "    lr_param_grid,\n",
    "    mlp_param_grid,\n",
    "    nb_param_grid\n",
    "]\n",
    "\n",
    "titles = [\n",
    "    \"RandomForestClassifier\",\n",
    "    \"DecisionTreeClassifier\", \n",
    "    \"GBTClassifier\",\n",
    "    \"LinearSVC\",\n",
    "    \"LogisticRegression\",\n",
    "    \"MultilayerPerceptronClassifier\",\n",
    "    \"NaiveBayes\"\n",
    "]\n",
    "\n",
    "# Assuming train_df and test_df are already defined\n",
    "model = compare_classifiers(classifiers, param_grids, train_df, test_df, titles)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9b5e5a24",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b410e53",
   "metadata": {},
   "source": [
    "- Charger Marketing"
   ]
  },
  {
   "cell_type": "code",
   "id": "93b6ab53-5731-458e-8ddf-70fddd426d58",
   "metadata": {},
   "source": [
    "from pyhive import hive\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "319ce2a0-fc7c-4625-a7ca-5af04fe7ce4c",
   "metadata": {},
   "source": [
    "hive_host = 'localhost'\n",
    "hive_port = 10000\n",
    "hive_username = ' ' \n",
    "hive_password = ' '"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7db13558-c4d1-4ca1-bc9d-cf35fe569c16",
   "metadata": {},
   "source": [
    "#conn = None\n",
    "try:\n",
    "    # Établir une connexion avec authentification LDAP\n",
    "    conn = hive.Connection(\n",
    "        host=hive_host,\n",
    "        port=hive_port,\n",
    "        username=hive_username,\n",
    "        password=hive_password,\n",
    "        auth='LDAP'  \n",
    "    )\n",
    "    print(\"Connecté à Hive avec succès\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la connexion à Hive: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "654b9d32-5456-4a8c-b3be-c30358142b55",
   "metadata": {},
   "source": [
    "# Créer un curseur\n",
    "cursor=conn.cursor()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "482b222c-499e-4855-9651-e29c56f5b2dc",
   "metadata": {},
   "source": [
    "def findAll(table) :\n",
    "    # Exécuter une requête pour récupérer les données de la table \"catalogue\"\n",
    "    query = \"SELECT * FROM \" + table\n",
    "    cursor.execute(query)\n",
    "\n",
    "    # Charger les résultats dans un DataFrame Pandas\n",
    "    data = cursor.fetchall()\n",
    "    columns = [desc[0] for desc in cursor.description] \n",
    "    df = spark.createDataFrame(data, schema=columns)\n",
    "    # df = spark.createDataFrame(pd_df)\n",
    "    \n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "328a68c9",
   "metadata": {},
   "source": [
    "marketing_df = findAll(\"marketing_view\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5ae8a830",
   "metadata": {},
   "source": [
    "Prétraiter les Données Marketing"
   ]
  },
  {
   "cell_type": "code",
   "id": "02cf9015-14c2-46a8-8e27-a332aa3e159f",
   "metadata": {},
   "source": [
    "# Renommer les colonnes pour éviter les conflits\n",
    "for column_name in marketing_df.columns:\n",
    "    marketing_df = marketing_df.withColumnRenamed(column_name, column_name.split(\".\")[-1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d369eb6d-f03b-4abe-99f4-c98285dba949",
   "metadata": {},
   "source": [
    "marketing_df.show(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "871c1dbf",
   "metadata": {},
   "source": [
    "Appliquer le Modèle de Prédiction"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd700b95-b813-45ac-9ef7-1de9392e65a3",
   "metadata": {},
   "source": [
    "marketing_df = pipeline_model.transform(marketing_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "198ddd14-31d6-42cb-9f00-f897e72cfa4b",
   "metadata": {},
   "source": [
    "marketing_df.show(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "66b51f69-3f21-4d4a-b67c-43292ed8fc6d",
   "metadata": {},
   "source": [
    "predictions = model.transform(marketing_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d9b14b2-5ac9-494a-a8ab-f103532521eb",
   "metadata": {},
   "source": [
    "# Sélectionner les colonnes pertinentes pour l'affichage\n",
    "for key, value in categorie_dict.items():\n",
    "    predictions = predictions.withColumn(\"prediction\", when(col('prediction') == key, value).otherwise(col('prediction')))\n",
    "\n",
    "results = predictions.select(\"id\", \"prediction\")\n",
    "\n",
    "results.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "526c0b6c",
   "metadata": {},
   "source": [
    "Exporter les Résultats"
   ]
  },
  {
   "cell_type": "code",
   "id": "efdda16c",
   "metadata": {},
   "source": [
    "# Chemin de sortie pour les résultats\n",
    "results_hdfs_path = \"hdfs:///tpa_groupe_14/results\"\n",
    "\n",
    "# Sauvegarder les résultats dans HDFS\n",
    "results.write.csv(results_hdfs_path, header=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c315b013-2b6b-43e4-89a9-e2b5121ac2bc",
   "metadata": {},
   "source": [
    "!hadoop fs -ls /tpa_groupe_14/results"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
